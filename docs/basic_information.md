# 我们这篇论文要解决的问题是什么？
模型是有时效性的，但我们的文化是一直在实时变化的。**所以模型的泛化能力能不能适应如此快速变化的网络亚文化表述** *(特定转义的“词句”)*？
我们要做的，就是证明大模型做不到适应（理解并提出可靠建议）这些文化表述，然后提出一个方法，这个方法能做到在不耗时耗力耗
钱的情况下，使得大模型能够适应文化表述的更新。

# 我们之前的人们做过什么工作？
Todo:
这一块我去看了我之前自己看过的论文，不是特别的匹配。我看的论文讲的是“心理治疗领域 & llm”的交叉，而我们现在做的事情其实是有点偏向“llm能否识别有心理问题的新兴亚文化的语句语义特征”。感觉我们的这个方向有细化到一定程度了，不太好找相关工作。不过我再看看。
**论文方向：**
用检索增强或多代理动态更新知识（RAG, tool-use, multi-agent curation）

# 我们为什么比他们强？


# 我们的具体的工作是怎么实现的？
通过 multiagents 的方法，用低廉的成本取得较好的能力。

我们采用第一性原理，从问题的根本出发，“llm的时效性不够”，那我们就从最具有时效性的网络出发，1. 我们从网络中搜寻亚文化的相关资料（根据亚文化的起源地语言搜索，并翻译成英文）。2. 我们通过`WebSearch Agent`把无关内容剔除掉。3. 我们使用`Report Agent`生成一个”Alignment Report"，它的作用就是“把**新兴的地雷女相关转义后的语句**和**传统意义上大模型理解的语句语义**做一个对齐。4. 我们利用 Jari Benchmark 进行对我们的"Alignment Report"的测试。4.1.首先进行语义对齐，然后做4.2.Harmful Jugdement，最后生成测试label。

所以，我们应该重视的是：
1. 我们怎么才能找到足够好的相关资料，这个相关资料凭什么足够好。这些所谓的数据资料，是不是还没我们的Jarai数据集好？我们直接用这个数据集的数据来做不行吗？
   - 或者说，这个思路是我们自己找地雷女的转义后的语句，然后通过大模型的能力来做翻译。
   - 另一个思路是找到那些介绍什么是地雷女的帖子文章，把他们这些已经处理过的文章拿过来做我们的Alignment Report养料？
2. 我们的agent凭什么怎么预处理这些资料，怎么判断哪些问题无关，怎么删掉?
   - 也全都交给大模型？直接让他自己判断？我们要做的所有事情就是把全文塞给他？
3. 我们怎么做这个Alignment Report，直接用大模型做Alignment？凭什么可以这样？因为新兴的大模型知道地雷女相关的知识？这是不是太草率了？就算直接用大模型来做Alignment的话，让大模型自己去判断哪些内容是地雷女相关？然后自己解释那些相关的内容的意思？

我们的架构是：
**Part A:**
Input Field -> Websearch Agent -> Research Results -> Report Agent -> Alignment Report ->
(这一部分就是我们现在要写的代码部分)
**Part B:**
subculture Alignment -->Harmful Judgement -> Final Label

# 我们怎么证明我们的工作比他们强的？
我们在Jirai Bechmark上的成绩比别的大模型好，或者说比同模型的zero-shots, few-shots, CoT效果好。